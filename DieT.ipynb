{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from transformers import DeiTForImageClassification, DeiTFeatureExtractor, get_scheduler\n",
    "\n",
    "# Define paths\n",
    "TRAIN_LABELED_CSV = \"./train_labeled.csv\"\n",
    "TRAIN_LABELED_DIR = \"./train/labeled\"\n",
    "TRAIN_UNLABELED_CSV = \"./train_unlabeled.csv\"\n",
    "TRAIN_UNLABELED_DIR = \"./train/unlabeled\"\n",
    "TEST_CSV = \"./test.csv\"\n",
    "TEST_DIR = \"./test\"\n",
    "CATEGORIES_CSV = \"./categories.csv\"\n",
    "MODEL_SAVE_PATH = \"./model.pth\"\n",
    "\n",
    "# Check if MPS is available and select the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define Dataset Class for Image Classification\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])  # Assuming filename is in the first column\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = int(self.data.iloc[idx, 1])  # Assuming label is in the second column\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Image Transformations for Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256),  # RandomCrop followed by Resize (Resize and RandomCrop to keep augmentation)\n",
    "    transforms.RandomHorizontalFlip(),  # Random Horizontal Flip for data augmentation\n",
    "    transforms.ToTensor(),              # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize based on ImageNet stats\n",
    "])\n",
    "\n",
    "# Load the Labeled Training Dataset\n",
    "train_labeled = CustomDataset(csv_file=TRAIN_LABELED_CSV, img_dir=TRAIN_LABELED_DIR, transform=transform)\n",
    "train_loader = DataLoader(train_labeled, batch_size=32, shuffle=True)\n",
    "\n",
    "# Load the DeiT Model and Feature Extractor\n",
    "model_name = 'facebook/deit-base-patch16-224-in21k'\n",
    "model = DeiTForImageClassification.from_pretrained(model_name, num_labels=len(pd.read_csv(CATEGORIES_CSV)))\n",
    "feature_extractor = DeiTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "model.to(device)  # Move the model to the device (CUDA or CPU)\n",
    "\n",
    "# Replace the final classifier head with the last two layers from DeiT\n",
    "# Extracting the penultimate layer and the final classification head from the model\n",
    "# First, we'll identify the layers\n",
    "last_two_layers = nn.Sequential(\n",
    "    model.deit.encoder.layer[-2],  # Penultimate block of the transformer encoder\n",
    "    model.deit.encoder.layer[-1],  # Final block of the transformer encoder\n",
    "    model.classifier  # Keep the original classifier head\n",
    ")\n",
    "\n",
    "# Reassign these layers back to the model\n",
    "model.deit.encoder.layer = nn.ModuleList(last_two_layers)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with learning rate and weight decay (as per your baseline)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "\n",
    "# Exponential decay for learning rate\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",  # Linear decay scheduler\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * 10  # Assume 10 epochs\n",
    ")\n",
    "\n",
    "model.to(device)  # Ensure the model is moved to the correct device\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Move inputs and labels to the device (CUDA/CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # Model will use the correct device\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs.logits, labels)  # Use logits from the model output\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        \n",
    "        # Update accuracy\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    # Print epoch loss and accuracy\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "# To load the model later:\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def get_predictions(model, test_path, transform, device):\n",
    "    predictions = []\n",
    "\n",
    "    # Loop through all the images in the test directory\n",
    "    for image_name in os.listdir(test_path):\n",
    "        if image_name.endswith('.jpg'):  # Assuming images are in JPG format\n",
    "            image_path = os.path.join(test_path, image_name)\n",
    "            \n",
    "            # Load and transform the image\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "            \n",
    "            # Move the image tensor to the same device as the model\n",
    "            image = image.to(device)\n",
    "\n",
    "            # Make the prediction\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                _, predicted_class = torch.max(output.logits, 1)  # Get the predicted class\n",
    "            \n",
    "            predictions.append((image_name, predicted_class.item()))  # Append the result\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Get predictions for all images in the test folder\n",
    "predictions = get_predictions(model, \"./test1/test\", transform, device)\n",
    "\n",
    "# Convert predictions to DataFrame and save as CSV\n",
    "df = pd.DataFrame(predictions, columns=['image', 'id'])\n",
    "df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 2.56k/2.56k [00:00<00:00, 3.92MB/s]\n",
      "Downloading data: 100%|██████████| 173k/173k [00:00<00:00, 2.76MB/s]\n",
      "Generating test split: 1 examples [00:00, 41.27 examples/s]\n",
      "Some weights of DeiTModel were not initialized from the model checkpoint at facebook/deit-base-distilled-patch16-224 and are newly initialized: ['deit.pooler.dense.bias', 'deit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 198, 768]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, DeiTModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\", trust_remote_code=True)\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "model = DeiTModel.from_pretrained(\"facebook/deit-base-distilled-patch16-224\")\n",
    "\n",
    "inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhurark/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Allocate a pipeline for sentiment-analysis\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('We are very happy to introduce pipeline to the transformers repository.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhurark/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tabby, tabby cat\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base-imagenet1k-1-layer')\n",
    "model = AutoModelForImageClassification.from_pretrained('facebook/dinov2-base-imagenet1k-1-layer')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
