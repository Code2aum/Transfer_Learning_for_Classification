{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6ec4dbe20474f4b986e3dd537ee47c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3c332f7188b462f955c491e23a5bf71",
              "IPY_MODEL_e63e1980b39445eca652d00731c85858",
              "IPY_MODEL_b71b9e577ca5400d828db1567503e4e3"
            ],
            "layout": "IPY_MODEL_61f5fe04a1034cfd80e4dc1cde9268be"
          }
        },
        "d3c332f7188b462f955c491e23a5bf71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c76f75cb6d44da1bf2514272a3a1dbe",
            "placeholder": "​",
            "style": "IPY_MODEL_51eefc144d964a28bdc3a9366aafca61",
            "value": "model.safetensors: 100%"
          }
        },
        "e63e1980b39445eca652d00731c85858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f4c25bbd2d46b69bffc969c998327a",
            "max": 800582904,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93408785c5f649c6b3da409facedabf0",
            "value": 800582904
          }
        },
        "b71b9e577ca5400d828db1567503e4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3773ebcf01dc42e4a72b1fd5ededfab2",
            "placeholder": "​",
            "style": "IPY_MODEL_45872ebca5294d0f97a9d80aebf7a7a8",
            "value": " 801M/801M [00:35&lt;00:00, 22.0MB/s]"
          }
        },
        "61f5fe04a1034cfd80e4dc1cde9268be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c76f75cb6d44da1bf2514272a3a1dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eefc144d964a28bdc3a9366aafca61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7f4c25bbd2d46b69bffc969c998327a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93408785c5f649c6b3da409facedabf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3773ebcf01dc42e4a72b1fd5ededfab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45872ebca5294d0f97a9d80aebf7a7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LCHX_fLzUFVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633f4313-e370-40aa-ad43-30cf39a86112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Wed Dec  4 20:35:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Installation and imports\n",
        "!pip install timm wandb\n",
        "!nvidia-smi # Check GPU\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip Dataset\n",
        "zip_path = '/content/drive/My Drive/DL_FinalProject.zip'\n",
        "extract_path = '/content/dataset'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CT8K67IbL19",
        "outputId": "45540946-2174-4976-a0e7-7eb904de4dc4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf '/content/dataset/__MACOSX'\n",
        "!ls '/content/dataset/DL_FinalProject'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQgk33uJe5Im",
        "outputId": "6ba55fda-cfb5-45b8-af16-55b72608cee7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories.csv\tsample_submission.csv  test  train  train_labeled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# Set device and random seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDJ_6KgJgaFm",
        "outputId": "b79ac0cc-c97c-41c5-d372-912560193bd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec  4 20:36:12 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class PlantDogDataset(Dataset):\n",
        "    def __init__(self, img_dir, csv_file=None, transform=None, is_labeled=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir (str): Directory with all the images.\n",
        "            csv_file (str): Path to the csv file with annotations.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            is_labeled (bool): Whether this is a labeled dataset.\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_labeled = is_labeled\n",
        "\n",
        "        if is_labeled and csv_file is not None:\n",
        "            self.data = pd.read_csv(csv_file)\n",
        "            if self.data.iloc[0, 1].dtype == 'O':  # If labels are strings\n",
        "                unique_labels = self.data.iloc[:, 1].unique()\n",
        "                self.label_map = {label: idx for idx, label in enumerate(sorted(unique_labels))}\n",
        "                self.data.iloc[:, 1] = self.data.iloc[:, 1].map(self.label_map)\n",
        "        else:\n",
        "            # For unlabeled data, just get list of image files\n",
        "            self.data = pd.DataFrame({\n",
        "                'filename': [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            if self.is_labeled:\n",
        "                img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
        "                label = self.data.iloc[idx, 1]\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "\n",
        "                return image, torch.tensor(label, dtype=torch.long)\n",
        "            else:\n",
        "                # Return both image and filename for unlabeled data\n",
        "                img_name = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
        "                image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "                if self.transform:\n",
        "                    image = self.transform(image)\n",
        "\n",
        "                # Return both the image tensor and the filename\n",
        "                return image, self.data.iloc[idx, 0]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image at index {idx}: {str(e)}\")\n",
        "            if self.is_labeled:\n",
        "                return torch.zeros((3, 224, 224)), torch.tensor(0, dtype=torch.long)\n",
        "            return torch.zeros((3, 224, 224)), \"\""
      ],
      "metadata": {
        "id": "-5zjjLu6cLWK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from timm.optim import create_optimizer_v2\n",
        "\n",
        "\n",
        "class SSLTrainer:\n",
        "    def __init__(self, train_loader, num_classes=135, num_epochs=10):\n",
        "        # Initialize Swin-L model\n",
        "        self.model = timm.create_model(\n",
        "            'swin_large_patch4_window12_384',\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,\n",
        "        )\n",
        "\n",
        "        # Freeze all layers first\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the last transformer stage\n",
        "        for param in self.model.layers[-1].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # Unfreeze the head\n",
        "        for param in self.model.head.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "        # Optimizer for unfrozen layers\n",
        "        param_groups = [\n",
        "            {'params': self.model.head.parameters(), 'lr': 8e-4},\n",
        "            {'params': self.model.layers[-1].parameters(), 'lr': 1.5e-4}\n",
        "        ]\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
        "        self.optimizer = create_optimizer_v2(\n",
        "            param_groups,\n",
        "            opt='adamw',\n",
        "            weight_decay=0.01,\n",
        "            betas=(0.9, 0.999)\n",
        "        )\n",
        "\n",
        "        # Scheduler with different max_lr for each parameter group\n",
        "        self.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "            self.optimizer,\n",
        "            max_lr=[5e-4, 1e-4],  # Different max_lr for each group\n",
        "            epochs=num_epochs,\n",
        "            steps_per_epoch=len(train_loader),\n",
        "            pct_start=0.15,\n",
        "            anneal_strategy='cos',\n",
        "            div_factor=15.0\n",
        "        )\n",
        "\n",
        "        self.scaler = GradScaler()\n",
        "\n",
        "    def train_epoch(self, labeled_loader, unlabeled_loader, epoch):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(zip(labeled_loader, unlabeled_loader),\n",
        "                  total=min(len(labeled_loader), len(unlabeled_loader)))\n",
        "\n",
        "        for i, (labeled_batch, unlabeled_batch) in enumerate(pbar):\n",
        "            if i % 10 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            labeled_images, labels = labeled_batch\n",
        "            labeled_images = labeled_images.to(device)\n",
        "            labels = labels.view(-1).long().to(device)\n",
        "\n",
        "            try:\n",
        "                if isinstance(unlabeled_batch, torch.Tensor):\n",
        "                    unlabeled_images = unlabeled_batch.to(device)\n",
        "                else:\n",
        "                    unlabeled_images = unlabeled_batch[0].to(device)\n",
        "\n",
        "                # Zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass and loss calculation inside autocast\n",
        "                with autocast():\n",
        "                    # Labeled data\n",
        "                    outputs = self.model(labeled_images)\n",
        "                    labeled_loss = self.criterion(outputs, labels)\n",
        "\n",
        "                    # Unlabeled data with higher confidence threshold\n",
        "                    unlabeled_outputs = self.model(unlabeled_images)\n",
        "                    pseudo_probs = torch.softmax(unlabeled_outputs, dim=1)\n",
        "                    max_probs, pseudo_labels = torch.max(pseudo_probs, dim=1)\n",
        "\n",
        "                    # Higher confidence threshold since we're using Swin-L\n",
        "                    confidence_threshold = 0.95\n",
        "                    mask = max_probs > confidence_threshold\n",
        "\n",
        "                    # Calculate unlabeled loss\n",
        "                    unlabeled_loss = torch.tensor(0.0, device=device)\n",
        "                    if torch.any(mask):\n",
        "                        confident_outputs = unlabeled_outputs[mask]\n",
        "                        confident_pseudo_labels = pseudo_labels[mask]\n",
        "                        unlabeled_loss = self.criterion(confident_outputs, confident_pseudo_labels)\n",
        "\n",
        "                    # Combined loss with reduced weight for unlabeled data\n",
        "                    loss = labeled_loss + 0.4 * unlabeled_loss\n",
        "\n",
        "                # Backward and optimize\n",
        "                self.scaler.scale(loss).backward()\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "\n",
        "                pred = torch.argmax(outputs, dim=1)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                pbar.set_description(\n",
        "                    f'Epoch {epoch} - Loss: {loss.item():.4f} - Acc: {100.*correct/total:.2f}%'\n",
        "                )\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"CUDA error in batch {i}: {e}\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "        avg_loss = total_loss / len(labeled_loader)\n",
        "        avg_acc = 100. * correct / total\n",
        "        return avg_loss, avg_acc\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(val_loader, desc='Validating'):\n",
        "                try:\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.view(-1).long().to(device)\n",
        "\n",
        "                    with autocast():\n",
        "                        outputs = self.model(images)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "                    pred = torch.argmax(outputs, dim=1)\n",
        "                    correct += (pred == labels).sum().item()\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"CUDA error in validation: {e}\")\n",
        "                    torch.cuda.empty_cache()\n",
        "                    continue\n",
        "\n",
        "        avg_loss = total_loss / len(val_loader)\n",
        "        avg_acc = 100. * correct / total\n",
        "        return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "z28IycQBcN2n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data transforms for SWIN model\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.RandomAutocontrast(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "JMardu5WdxhM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def predict_test(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Generate predictions for test data.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        test_loader: DataLoader for test dataset.\n",
        "        device: Device to perform computation on (e.g., \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        predictions: List of predicted category IDs.\n",
        "        filenames: List of corresponding image filenames.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    filenames = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, file_ids in tqdm(test_loader, desc=\"Predicting test data\"):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted class IDs\n",
        "            predictions.extend(preds.cpu().numpy())  # Convert to NumPy array\n",
        "            filenames.extend(file_ids)  # Collect filenames\n",
        "\n",
        "    return predictions, filenames\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_submission(model, test_dir, categories_file, val_transform, device, output_csv=\"submission.csv\"):\n",
        "    \"\"\"\n",
        "    Create submission file for Kaggle.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        test_dir: Directory containing test images.\n",
        "        categories_file: Path to the file mapping category IDs to category names.\n",
        "        val_transform: Transformations applied to test images.\n",
        "        device: Device to perform computation on.\n",
        "        output_csv: Name of the output CSV file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Load categories mapping\n",
        "    categories_df = pd.read_csv(categories_file)\n",
        "    id_to_category = dict(zip(range(len(categories_df)), categories_df['category']))\n",
        "\n",
        "    # Create test dataset and DataLoader\n",
        "    test_dataset = PlantDogDataset(\n",
        "        img_dir=test_dir,\n",
        "        transform=val_transform,\n",
        "        is_labeled=False\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Generate predictions and filenames\n",
        "    predictions, filenames = predict_test(model, test_loader, device)\n",
        "\n",
        "    # Map predictions to category names\n",
        "    category_predictions = [id_to_category[pred] for pred in predictions]\n",
        "\n",
        "    # Create submission DataFrame\n",
        "    submission_df = pd.DataFrame({\n",
        "        'image': filenames,\n",
        "        'id': predictions\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    submission_file = os.path.join(os.getcwd(), output_csv)\n",
        "    submission_df.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved to: {submission_file}\")\n"
      ],
      "metadata": {
        "id": "GAwWDYeoIYCq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "def main():\n",
        "    # Set random seed for reproducibility\n",
        "    set_seed(42)\n",
        "\n",
        "    # Set paths\n",
        "    base_path = '/content/dataset/DL_FinalProject'\n",
        "    labeled_dir = os.path.join(base_path, 'train/labeled')\n",
        "    unlabeled_dir = os.path.join(base_path, 'train/unlabeled')\n",
        "    test_dir = os.path.join(base_path, 'test')\n",
        "    train_csv = os.path.join(base_path, 'train_labeled.csv')\n",
        "    categories_file = os.path.join(base_path, 'categories.csv')  # Ensure this file exists\n",
        "\n",
        "    # Define transformations for train, validation, and test (384x384 for Swin-L)\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "        transforms.RandomAutocontrast(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((384, 384)),\n",
        "        transforms.CenterCrop(384),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = PlantDogDataset(\n",
        "        img_dir=labeled_dir,\n",
        "        csv_file=train_csv,\n",
        "        transform=train_transform,\n",
        "        is_labeled=True\n",
        "    )\n",
        "\n",
        "    # Split labeled dataset into training and validation sets\n",
        "    train_size = int(0.9 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        train_dataset, [train_size, val_size]\n",
        "    )\n",
        "\n",
        "    # Create unlabeled dataset\n",
        "    unlabeled_dataset = PlantDogDataset(\n",
        "        img_dir=unlabeled_dir,\n",
        "        transform=train_transform,\n",
        "        is_labeled=False\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    unlabeled_loader = DataLoader(\n",
        "        unlabeled_dataset,\n",
        "        batch_size=4,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "    print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "    print(f\"Number of unlabeled samples: {len(unlabeled_dataset)}\")\n",
        "\n",
        "    # Initialize SSL trainer (you should have this class in your code)\n",
        "    trainer = SSLTrainer(train_loader=train_loader, num_classes=135, num_epochs=10)\n",
        "    num_epochs = 10\n",
        "    best_val_acc = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        torch.cuda.empty_cache()  # Clear CUDA memory to prevent out-of-memory errors\n",
        "\n",
        "        train_loss, train_acc = trainer.train_epoch(train_loader, unlabeled_loader, epoch)\n",
        "        val_loss, val_acc = trainer.validate(val_loader)\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        trainer.scheduler.step()\n",
        "\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': trainer.model.state_dict(),\n",
        "                'optimizer_state_dict': trainer.optimizer.state_dict(),\n",
        "                'best_val_acc': best_val_acc,\n",
        "            }, 'best_model.pth')\n",
        "            print(f\"Best model saved with validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "        print('-' * 50)\n",
        "\n",
        "    # Load the best model for submission\n",
        "    best_model_path = 'best_model.pth'\n",
        "    if os.path.exists(best_model_path):\n",
        "        checkpoint = torch.load(best_model_path)\n",
        "        trainer.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        trainer.model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "        print(f\"Loaded best model from epoch {checkpoint['epoch']} with validation accuracy {checkpoint['best_val_acc']:.2f}%\")\n",
        "\n",
        "    # Generate submission file\n",
        "    create_submission(\n",
        "        model=trainer.model,\n",
        "        test_dir=test_dir,\n",
        "        categories_file=categories_file,\n",
        "        val_transform=val_transform,\n",
        "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    )\n",
        "    print(\"Submission generation complete.\")\n",
        "    print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6ec4dbe20474f4b986e3dd537ee47c4",
            "d3c332f7188b462f955c491e23a5bf71",
            "e63e1980b39445eca652d00731c85858",
            "b71b9e577ca5400d828db1567503e4e3",
            "61f5fe04a1034cfd80e4dc1cde9268be",
            "2c76f75cb6d44da1bf2514272a3a1dbe",
            "51eefc144d964a28bdc3a9366aafca61",
            "f7f4c25bbd2d46b69bffc969c998327a",
            "93408785c5f649c6b3da409facedabf0",
            "3773ebcf01dc42e4a72b1fd5ededfab2",
            "45872ebca5294d0f97a9d80aebf7a7a8"
          ]
        },
        "id": "ZlHFsYs5hfvM",
        "outputId": "500878bb-8f69-486f-c06e-fa19c74b1f91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 8868\n",
            "Number of validation samples: 986\n",
            "Number of unlabeled samples: 22995\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/801M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6ec4dbe20474f4b986e3dd537ee47c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 - Loss: 1.8708 - Acc: 58.34%: 100%|██████████| 2217/2217 [13:14<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10:\n",
            "Train Loss: 2.8724, Train Acc: 58.34%\n",
            "Val Loss: 1.6800, Val Acc: 86.11%\n",
            "Best model saved with validation accuracy: 86.11%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Loss: 1.4129 - Acc: 87.73%: 100%|██████████| 2217/2217 [13:14<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/10:\n",
            "Train Loss: 1.7045, Train Acc: 87.73%\n",
            "Val Loss: 1.5083, Val Acc: 89.55%\n",
            "Best model saved with validation accuracy: 89.55%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Loss: 1.6384 - Acc: 90.87%: 100%|██████████| 2217/2217 [13:14<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/10:\n",
            "Train Loss: 1.5708, Train Acc: 90.87%\n",
            "Val Loss: 1.4717, Val Acc: 89.96%\n",
            "Best model saved with validation accuracy: 89.96%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Loss: 2.2760 - Acc: 92.94%: 100%|██████████| 2217/2217 [13:14<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/10:\n",
            "Train Loss: 1.4962, Train Acc: 92.94%\n",
            "Val Loss: 1.4416, Val Acc: 90.77%\n",
            "Best model saved with validation accuracy: 90.77%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Loss: 2.2927 - Acc: 94.16%: 100%|██████████| 2217/2217 [13:14<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/10:\n",
            "Train Loss: 1.4508, Train Acc: 94.16%\n",
            "Val Loss: 1.4282, Val Acc: 91.89%\n",
            "Best model saved with validation accuracy: 91.89%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Loss: 1.2234 - Acc: 95.33%: 100%|██████████| 2217/2217 [13:12<00:00,  2.80it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/10:\n",
            "Train Loss: 1.4081, Train Acc: 95.33%\n",
            "Val Loss: 1.4133, Val Acc: 92.19%\n",
            "Best model saved with validation accuracy: 92.19%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Loss: 1.1839 - Acc: 96.17%: 100%|██████████| 2217/2217 [13:13<00:00,  2.79it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/10:\n",
            "Train Loss: 1.3840, Train Acc: 96.17%\n",
            "Val Loss: 1.4003, Val Acc: 92.60%\n",
            "Best model saved with validation accuracy: 92.60%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Loss: 1.2224 - Acc: 96.70%: 100%|██████████| 2217/2217 [13:12<00:00,  2.80it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/10:\n",
            "Train Loss: 1.3568, Train Acc: 96.70%\n",
            "Val Loss: 1.3814, Val Acc: 92.90%\n",
            "Best model saved with validation accuracy: 92.90%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Loss: 1.2423 - Acc: 97.30%: 100%|██████████| 2217/2217 [13:12<00:00,  2.80it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/10:\n",
            "Train Loss: 1.3369, Train Acc: 97.30%\n",
            "Val Loss: 1.3867, Val Acc: 93.31%\n",
            "Best model saved with validation accuracy: 93.31%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Loss: 1.2250 - Acc: 97.83%: 100%|██████████| 2217/2217 [13:12<00:00,  2.80it/s]\n",
            "Validating: 100%|██████████| 247/247 [00:37<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/10:\n",
            "Train Loss: 1.3200, Train Acc: 97.83%\n",
            "Val Loss: 1.3875, Val Acc: 92.49%\n",
            "--------------------------------------------------\n",
            "Loaded best model from epoch 8 with validation accuracy 93.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting test data: 100%|██████████| 257/257 [10:50<00:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved to: /content/submission.csv\n",
            "Submission generation complete.\n",
            "Current working directory: /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Current working directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "BeHNVKyLkbxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414d9d57-287e-4b6f-fb85-44391035c43d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZst6hhDJkS5",
        "outputId": "e4d4be99-d942-4523-c218-185725cc559b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.pth\tdataset  drive\tsample_data  submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/DL_Submission\n"
      ],
      "metadata": {
        "id": "1qN0lGnVJmrM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/best_model.pth /content/drive/MyDrive/DL_Submission/best_model.pth\n",
        "!cp /content/submission.csv /content/drive/MyDrive/DL_Submission/submission_10e.csv\n"
      ],
      "metadata": {
        "id": "aYUarxTlrhWd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read both the submission and categories files\n",
        "df = pd.read_csv('/content/submission.csv')\n",
        "categories_df = pd.read_csv('/content/dataset/DL_FinalProject/categories.csv')\n",
        "\n",
        "# Create a mapping from category names to category IDs\n",
        "category_to_id = dict(zip(categories_df['category'], categories_df.index))\n",
        "\n",
        "# Convert string categories to numeric IDs using the mapping\n",
        "# Only do this if the id column contains strings\n",
        "if df['id'].dtype == 'object':  # if the column contains strings\n",
        "    df['id'] = df['id'].map(category_to_id)\n",
        "\n",
        "# Ensure we have the right columns in the right order\n",
        "df = df[['image', 'id']]\n",
        "\n",
        "# Ensure id column is integer type\n",
        "df['id'] = df['id'].astype(int)\n",
        "\n",
        "# Save with the exact format needed, without index\n",
        "df.to_csv('/content/drive/MyDrive/DL_Submission/formatted_submission_swinL_10e.csv', index=False)\n",
        "\n",
        "# Verify the format\n",
        "print(\"\\nFirst few rows of the reformatted submission:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cM4QmUlrlUn",
        "outputId": "b055c899-2d5c-464f-c390-4b1e8c6715ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few rows of the reformatted submission:\n",
            "       image   id\n",
            "0  40237.jpg  106\n",
            "1  39976.jpg    9\n",
            "2  39162.jpg    6\n",
            "3  40543.jpg   26\n",
            "4  34094.jpg    2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F40xnDr_vQOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}